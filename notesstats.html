<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Notes on Statistics</title>
    <link rel="stylesheet" href="styles/styles.css">
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>

<body>

    <span><b>Notes on Statistics</b></span>

    <p>
        I will avoid rigor; the emphasis of these notes is on practical statistics. However, it is sometimes helpful for
        me to state definitions in a more mathematically precise form than what is found in most non-mathematical
        sources, because it helps ease an itchy feeling.
    </p>

    <p>
        Most of the information presented here has been taken verbatim from the following sources:
    </p>

    <ul>
        <li>
            Hartmann, K., Krois, J., & Rudolph, A. (2023). <em>Statistics and Geodata Analysis using R</em>.
            <a href="https://www.geo.fu-berlin.de/soga-r" target="_blank">SOGA-R</a>
        </li>
        <li>
            Rudolph, A., Krois, J., & Hartmann, K. (2023). <em>Statistics and Geodata Analysis using Python</em>.
            <a href="https://www.geo.fu-berlin.de/soga-py" target="_blank">SOGA-Py</a>
        </li>
        <li>
            The website <a href="http://www.randomservices.org/random/" target="_blank">Random</a>
        </li>
        <li>
            DeGroot, M. H., & Schervish, M. J. (2012). <em>Probability and Statistics</em> (4th ed.). Addison-Wesley.
        </li>
        <li>
            Diez, D. M., Çetinkaya-Rundel, M., & Barr, C. D. (2019). <em>OpenIntro Statistics</em> (4th ed.). OpenIntro.
        </li>
    </ul>

    <p>These notes are broadly organized as follows:</p>

    <ul>
        <li><a href="#CDFQuantile">Distribution and quantile functions</a></li>
        <li><a href="#Hypotheses">Hypotheses</a></li>
        <li><a href="#ErrorSignificance">Error and Significance Level</a></li>
        <li><a href="#CriticalValuePValue">Critical Value and the p-Value</a></li>
        <li><a href="#OnePopulationMeanKnownSigma">Inference for One Population Mean with Known Sigma</a></li>
        <li><a href="#OnePopulationMeanUnknownSigma">Inference for One Population Mean with Unknown Sigma</a></li>
        <li><a href="#TwoPopulationMeansEqualSD">Inference for Two Independent Population Means with Equal Standard
                Deviations</a></li>
        <li><a href="#TwoPopulationMeansUnequalSD">Inference for Two Independent Population Means with Unequal Standard
                Deviations</a></li>
    </ul>

    <hr>

    <span id="CDFQuantile"><b>Distribution and quantile functions</b></span>

    <p>
        There are several definitions of a quantile for a dataset, and they are not necessarily equivalent.
        This nuance is often overlooked. In many cases, the differences between these definitions are small,
        but when sample values are far apart, such as in the long tail of a distribution, the differences can be
        substantial. We will first focus on the more general, single mathematical notion of a quantile.
    </p>

    <p>
        Suppose that \(X\) is a real-valued random variable. The <i>(cumulative) distribution function</i> (CDF) of
        \(X\) is the function \(F: \mathbb{R} \to [0, 1]\) defined by
        \[
        F(x) = \mathbb{P}(X \le x), \quad x \in \mathbb{R}
        \]
    </p>

    <p>
        For \(p \in (0,1)\), any value \(x\) satisfying \(\mathbb{P}(X < x) \le p\) and \(F(x)=\mathbb{P}(X \le x) \ge
            p\) is called a <i>quantile</i> of order \(p\) for the distribution.
    </p>

    <p>
        The <i>quantile function</i> \(F^{-1}\) of \(X\) is defined by
        \[
        F^{-1}(p) = \min\{x \in \mathbb{R}: F(x) \ge p\}, \quad p \in (0, 1)
        \]
    </p>

    <p>
        In Python, you can compute quantiles and CDF values using the <code>scipy.stats</code> library, which provides
        functions for various probability distributions. For example, for the normal distribution you have:
    </p>

    <pre class="plain"><code>import scipy.stats as stats

mu = 0  
sigma = 1 

x = 1
cdf_value = stats.norm.cdf(x, loc=mu, scale=sigma)

p = 0.7
quantile_value = stats.norm.ppf(p, loc=mu, scale=sigma)</code></pre>

    <hr>

    <span id="Hypotheses"><b>Hypotheses</b></span>

    <p>
        In statistical <i>hypothesis testing</i>, the goal is to determine whether there is sufficient
        evidence to reject a presumed <i>null hypothesis</i> in favor of a conjectured <i>alternative hypothesis</i>.
        The null hypothesis is usually denoted by \(H_0\), while the alternative hypothesis is usually
        denoted by \(H_1\).
    </p>

    <p>
        For example, if the hypothesis test concerns deciding whether a population mean \(\mu\)
        differs from a specified value \(\mu_0\), then the null hypothesis can be expressed as
        \[
        H_0: \mu = \mu_0
        \]
    </p>

    <p>
        and the alternative hypothesis as
        \[
        H_1: \mu \neq \mu_0\text{.}
        \]
    </p>

    <p>Such a hypothesis test is called a <b>two-sided test</b>.</p>

    <p>
        If the hypothesis test is about deciding whether a population mean \(\mu\)
        is smaller than the specified value \(\mu_0\), the alternative hypothesis is expressed as
        \[
        H_1: \mu < \mu_0\text{.} \] </p>

            <p>Such a hypothesis test is called a <b>left-tailed test</b>.</p>

            <p>
                Analogously, we have the <b>right-tailed test</b>, which is about deciding whether a population mean
                \(\mu\) is greater than the specified value \(\mu_0\).
            </p>

            <p>
                We make the decision to reject the null hypothesis in favor of the alternative,
                or to not reject the null hypothesis, based on the observed outcome, say \(\mathbf{x}\), of a random
                experiment.
                We identify an appropriate subset \(R\) of the sample space \(S\) and reject \(H_0\) if and
                only if \(\mathbf{x} \in R\).
                This set \(R\) is known as the <b>rejection region</b> or the <b>critical region</b>. However, we will
                see that this
                critical region is often defined in terms of a <i>test statistic</i>, which maps \(S\) into another set
                \(T\). This allows
                for siginificant data reduction.
            </p>

            <hr>

            <span id="ErrorSignificance"><b>Error and Significance Level</b></span>

            <p>
                Conducting a hypothesis test always implies, that there is a chance of making an incorrect decision.
                There are two types of errors, depending on which of the hypotheses is actually true.
                A <b>type I error</b> occurs when a true null hypothesis is rejected (a <i>false positive</i>),
                while a <b>type II error</b> occurs when a false null hypothesis is not rejected (a <i>false
                    negative</i>).
                Similarly, there are two ways to make a correct decision. The possibilities are summarized in the
                following table:
            </p>

            <div class="scrollable" style="font-size: smaller;">
                <div>
                    <table>
                        <tr>
                            <td><b>Decision / State</b></td>
                            <td>\(H_0\) is true</td>
                            <td>\(H_0\) is false</td>
                        </tr>
                        <tr>
                            <td>Do not reject \(H_0\)</td>
                            <td>Correct decision</td>
                            <td>Type II error</td>
                        </tr>
                        <tr>
                            <td>Reject \(H_0\)</td>
                            <td>Type I error</td>
                            <td>Correct decision</td>
                        </tr>
                    </table>
                </div>
            </div>

            <p>
                The probability of a type I error is commonly called the
                <b>significance level</b> of the hypothesis test and is denoted by \(\alpha\).
                If \(H_0\) is a composite hypothesis, then it specifies a variety of
                different distributions, and thus there is a set of type I error probabilities. In this
                case, the significance level is the maximum probability of a type I error over
                this set of distributions.
            </p>

            <p>
                The probability of a type II error is denoted by \(\beta\). Generally, there is
                a tradeoff between type I and type II error probabilities. If we reduce the probability
                of a type I error by making the rejection region smaller, we necessarily increase the
                probability of a type II error because the complementary region \(S \setminus R\) becomes larger.
            </p>

            <p>
                If a hypothesis test is performed at a certain significance level \(\alpha\) and the null
                hypothesis is rejected, one may state that the test results are
                <b>statistically significant at the \(\alpha\) level</b>. If the null
                hypothesis is not rejected at significance level \(\alpha\), one may state
                that the test results are <b>not statistically significant at the \(\alpha\) level.</b>
            </p>

            <p><i>More on the power of a test later!</i></p>

            <hr>

            <span id="CriticalValuePValue"><b>Critical Value and the p-Value</b></span>

            <p>
                Under the <b>critical value approach</b>, the test statistic,
                calculated based on the observed data, is compared to a certain critical value.
                If the test statistic is more <i>extreme</i> than the critical value, the null hypothesis
                is rejected; otherwise, it is not.
            </p>

            <p>
                This critical value is computed based on the given significance level \(\alpha\) and
                the probability distribution specified by \(H_0\).
            </p>

            <p>
                Let us consider the simpler case in which \(H_0\) is not composite and the distribution
                it specifies is a bell-shaped normal distribution. The critical value divides the area under
                the probability distribution curve into the rejection region(s) and the non-rejection region.
            </p>

            <p>
                In a two-sided test, the null hypothesis is rejected
                if the test statistic is either too small or too large.
                Thus, the rejection region for such a test consists of two parts: one on the left and one on the right.
            </p>

            <div class="img-div">
                <img src="images/two_sided_critical_value.png" alt="two-sided critical value">
            </div>

            <p>
                For a left-tailed test, the null hypothesis is rejected if the test statistic is too small. Thus, the
                rejection region for such a test consists of one part, which is to the left of the center.
            </p>

            <div class="img-div">
                <img src="images/left_sided_critical_value.png" alt="left-tailed critical value">
            </div>

            <p>
                For a right-tailed test, the null hypothesis is rejected if the test statistic is too large. Thus, the
                rejection region for such a test consists of one part, which is to the right of the center.
            </p>

            <div class="img-div">
                <img src="images/right_sided_critical_value.png" alt="right-tailed critical value">
            </div>

            <p>
                In most cases, we have a general procedure that allows us to
                construct a test (that is, a rejection region \(R_{\alpha}\)) for any given
                significance level \(\alpha \in (0,1)\). Typically, \(R_{\alpha}\) decreases (in the subset sense)
                as \(\alpha\) decreases.
            </p>

            <p>
                The <b>\(\mathbf{p}\)-value</b> of the observed value \(x\) is defined to be the smallest
                \(\alpha\) for which \(x \in R_{\alpha}\), that is, the smallest significance level for which
                \(H_0\) is rejected, given the observed value \(x\).
            </p>

            <p>
                Let us denote this \(p\)-value by \(P(x)\). Knowing \(P(x)\) allows us to test \(H_0\) at
                any significance level for the given data \(x\): if \(P(x) \leq \alpha\), then we
                would reject \(H_0\) at significance level \(\alpha\); if \(P(x) > \alpha\), then we fail
                to reject \(H_0\) at significance level \(\alpha\).
            </p>

            <p>
                Informally, the p-value corresponds to the probability of observing sample data at least as extreme as
                the actually obtained test statistic. Small p-values provide evidence against the null hypothesis. The
                smaller (closer to 0) the p-value, the stronger the evidence against the null hypothesis.
            </p>

            <hr>

            <span id="OnePopulationMeanKnownSigma"><b>Inference for One Population Mean with Known Sigma</b></span>

            <p>
                The simplest form of hypothesis test is the test for one population mean.
                If the population standard deviation \(\sigma\) is known, a hypothesis test for one population mean is
                called <b>one-mean \(\mathbf{z}\)-Test</b> or simply <b>\(\mathbf{z}\)-Test</b>.
            </p>

            <p>
                To perform the \(z\)-test we follow the step-wise procedure shown below. First, we showcase the critical
                value approach. Secondly, we repeat the analysis for the \(p\)-value approach.
            </p>

            <ol>
                <li>State the null hypothesis \(H_0\) and the alternative hypothesis \(H_A\).</li>
                <li>Decide on the significance level, \(\alpha\).</li>
                <li>Compute the value of the test statistic.</li>
                <li>Under the critical value approach, determine the critical value. <br>
                    Under the p-value approach, determine the \(p\)-value.</li>
                <li>
                    Critical value approach: If the value of the test statistic falls in the rejection region, reject
                    \(H_0\); otherwise, do not reject \(H_0\). <br>
                    \(p\)-value approach: If \(p \leq \alpha\), reject \(H_0\); otherwise, do not reject \(H_0\).
                </li>
                <li>Interpret the result of the hypothesis test.</li>
            </ol>

            <p>
                We will work with the <i>students</i> dataset in Python:
            </p>
            <pre class="plain"><code>>>> import pandas as pd
>>> import numpy as np
>>> students = pd.read_csv("https://userpage.fu-berlin.de/soga/data/raw-data/students.csv")</code></pre>

            <p>
                The <i>students</i> dataset contains 8,239 rows, each representing an individual student, and 16
                columns, each corresponding to a variable or feature related to that student:
            </p>
            <pre class="plain"><code>>>> students.head(5)
   stud.id                 name       gender  age  ...  score2  online.tutorial graduated  salary
1   833917  Gonzales, Christina  Female   19  ...     NaN                0         0     NaN
2   898539       Lozano, T'Hani  Female   19  ...     NaN                0         0     NaN
3   379678       Williams, Hanh  Female   22  ...    46.0                0         0     NaN
4   807564          Nem, Denzel    Male   19  ...     NaN                0         0     NaN
5   383291      Powell, Heather  Female   21  ...     NaN                0         0     NaN

[5 rows x 16 columns]</code></pre>

            <p>
                In this analysis, we will examine the average weight of students and compare it to the average weight of
                European adults. It has been reported that the average body mass of the European adult population is
                70.8 kg. Since the standard deviation is not known, we will assume it to be equal to the standard
                deviation of the "weight" variable in the <i>students</i> dataset:
            </p>
            <pre class="plain"><code>>>> mu_0 = 70.8
>>> sigma = np.std(students["weight"])
>>> print(round(sigma, 2))
8.63</code></pre>

            <p>
                Next, we will take a random sample of 14 students:
            </p>
            <pre class="plain"><code>>>> n = 14
>>> sample_weights = students.sample(n, random_state=8)["weight"]
>>> mean_sample = np.mean(sample_weights)
>>> print(round(mean_sample, 2))
69.82</code></pre>

            <p>
                The null hypothesis is \(H_0: \mu = 70.8\), and we have three possible alternative hypotheses:
                \(H_{A_1}: \mu \neq 70.8\), \(H_{A_2}: \mu < 70.8\), and \(H_{A_3}: \mu> 70.8\).
            </p>

            <p>
                Let the significance level be \(\alpha = 0.05\):
            </p>
            <pre class="plain"><code>>>> alpha = 0.05</code></pre>

            <p>
                The test statistic \(z\) is defined as \(z = \frac{\bar{x} - \mu_0}{\sigma / \sqrt{n}}\). Applying this
                formula to our data, we have:
            </p>
            <pre class="plain"><code>>>> z = (mean_sample - mu_0) / (sigma / np.sqrt(n))
>>> print(z)
-0.42404547484536753</code></pre>

            <p>
                To calculate the critical values, we use the <code>norm.ppf()</code> function from the
                <code>scipy</code> package. Since we are testing three alternative hypotheses (\(H_{A_1}\), \(H_{A_2}\),
                and \(H_{A_3}\)), we need to calculate three corresponding critical values:
                \(z_{A_1} = \pm z_{\alpha / 2}\), \(z_{A_2} = -z_\alpha\), and \(z_{A_3} = +z_\alpha\):
            </p>
            <pre class="plain"><code>>>> z_ha1 = norm.ppf(alpha / 2)
>>> z_ha2 = norm.ppf(alpha)
>>> z_ha3 = norm.ppf(1 - alpha)
>>> print(z_ha1, z_ha2, z_ha3)
-1.9599639845400545 -1.6448536269514729 1.6448536269514722</code></pre>

            <p>
                Does the test statistic fall in the rejection region for \(H_{A_1}\)?
            </p>
            <pre class="plain"><code>>>> print(z < z_ha1 or z > np.abs(z_ha1))
False</code></pre>

            <p>
                At the 5% significance level, we fail to reject \(H_0\).
            </p>

            <p>
                Does the test statistic fall in the rejection region for \(H_{A_2}\)?
            </p>
            <pre class="plain"><code>>>> print(z < z_ha2)
False</code></pre>

            <p>
                Again, at the 5% significance level, we fail to reject \(H_0\).
            </p>

            <p>
                Does the test statistic fall in the rejection region for \(H_{A_3}\)?
            </p>
            <pre class="plain"><code>>>> print(z > z_ha3)
False</code></pre>

            <p>
                Once more, at the 5% significance level, we fail to reject \(H_0\).
            </p>

            <p>
                Under the \(p\)-value approach, we still require the test statistic \(z\),
                which we have already calculated. To calculate the \(p\)-value using Python, we apply the
                <code>norm.cdf()</code> function from the scipy package to compute the probability of occurrence for the
                test statistic based on the standard normal distribution. Since we are testing three alternative
                hypotheses (\(H_{A_1}\), \(H_{A_2}\), and \(H_{A_3}\)), we need to calculate three \(p\)-values as well:
            </p>

            <pre class="plain"><code>>>> lower = norm.cdf(z)
>>> upper = 1 - norm.cdf(np.abs(z))
>>> p_value_1 = lower + upper
>>> p_value_2 = norm.cdf(z)
>>> p_value_3 = 1 - norm.cdf(z)
>>> print(p_value_1, p_value_2, p_value_3)
0.6715326491107156 0.3357663245553578 0.6642336754446422</code></pre>

            <p>
                Again, at the 5% significance level, we fail to reject \(H_0\), since:
            </p>

            <pre class="plain"><code>>>> print(p_value_1 <= alpha, p_value_2 <= alpha, p_value_3 <= alpha)
False False False</code></pre>


            <p>
                The primary assumption that we made is that the underlying sampling distribution is normal. Of course,
                in real statistical problems, we are unlikely to know much about the sampling distribution, let alone
                whether or not it is normal. Suppose in fact that the underlying distribution is not normal. When the
                sample size \(n\) is relatively large, the distribution of the sample mean will still be approximately
                normal by the central limit theorem, and thus our tests of the mean \(\mu\) should still be
                approximately
                valid.
            </p>

            <hr>

            <span id="OnePopulationMeanUnknownSigma"><b>Inference for One Population Mean with Unknown Sigma</b></span>

            <p>
                A hypothesis test for a population mean, when the population standard deviation \(\sigma\) is unknown,
                is conducted in the same way as if the population standard deviation were known. However, we need to
                consider the sample standard deviation \(s\) in addition, and the test statistic, denoted by \(t\), is
                defined as follows: \[t = \frac{\bar{x} - \mu_0}{s / \sqrt{n}}\text{.}\]
            </p>

            <p>
                This test statistic is called the Student's \(t\)-distribution with \(n-1\) degrees of freedom.
            </p>

            <p>
                We will again consider the <i>students</i> data set. We will examine the average
                weight of a random sample of students and compare it to the average weight of European adults.
                We will not showcase the critical value approach. For the p-value approach, we will use the
                <code>stats.ttest_1samp()</code> function from the <code>scipy</code> package.
            </p>

            <p>
                We set the population mean accordingly: \(μ_0=70.8\). Further, we take a random sample
                (<code>sample_weights</code>) with
                a sample size of \(n=9\). The sample consists of the weights in kg of 9 randomly picked students from
                the
                students data set.
            </p>

            <pre class="plain"><code>>>> import pandas as pd
>>> import numpy as np
>>> students = pd.read_csv("https://userpage.fu-berlin.de/soga/data/raw-data/students.csv")
>>> mu_0 = 70.8
>>> n = 9
>>> sample_weights = students.sample(n, random_state = 9)["weight"]</code></pre>

            <p>
                The following code performs a one-sample t-test. The test is two-sided, and the result
                includes the t-statistic, p-value, and degrees of freedom.
            </p>

            <pre
                class="plain"><code>>>> from scipy import stats
>>> test_result = stats.ttest_1samp(sample_weights,
...                                 mu_0,
...                                 alternative = "two-sided")
>>> 
>>> 
>>> test_result
TtestResult(statistic=np.float64(1.1620080498483334), pvalue=np.float64(0.2787240885983498), df=np.int64(8))</code></pre>

            <p>
                We fail to reject the null hypothesis at the \(0.05\) significance level, since the p-value is greater
                than \(0.05\).
            </p>

            <hr>

            <span id="TwoPopulationMeansEqualSD"><b>Inference for Two Independent Population Means with Equal Standard
                    Deviations</b></span>

            <p>
                So far, we have focused on hypothesis tests for one population mean. However, in many applications, we
                want to compare the means of two or more populations. Therefore, we first need to distinguish between
                samples from two independent populations and samples from populations that are not independent, which
                are called paired samples.
            </p>

            <p>
                We assume that the standard deviations of the two populations are equal but unknown. If, however, the
                population standard deviation
                \(\sigma\) were known, the test statistic could be written as follows:
                \[
                z = \frac{(\bar{x}_{1} - \bar{x}_{2}) - (\mu_{1} - \mu_{2})}
                {\sigma \sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}}
                \]
            </p>

            <p>
                In most real-world applications, \(\sigma\) is unknown and must therefore be estimated. A natural
                approach is to use the sample variances
                \(s_1^2\) and \(s_2^2\) as estimates of \(\sigma^2\). By pooling these variances and weighting them
                according to their respective sample sizes,
                we obtain the following estimate of \(\sigma\):
                \[
                s_{p} = \sqrt{\frac{(n_{1} - 1)s_{1}^{2} + (n_{2} - 1)s_{2}^{2}}{n_{1} + n_{2} - 2}}.
                \]
            </p>

            <p>
                The quantity \(s_p\) is called the <em>pooled sample standard deviation</em>, where the subscript \(p\)
                denotes pooling.
            </p>

            <p>
                Replacing \(\sigma\) in the test statistic with its estimate \(s_p\) yields:
                \[
                t = \frac{(\bar{x}_{1} - \bar{x}_{2}) - (\mu_{1} - \mu_{2})}{s_{p} \sqrt{\frac{1}{n_{1}} +
                \frac{1}{n_{2}}}}
                \]
            </p>

            <p>
                The denominator of this expression, \(s_p \sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}\), is an estimator of
                the standard deviation of \(\bar{x}_{1} - \bar{x}_{2}\), which can be written as \(s_{\bar{x}_{1} -
                \bar{x}_{2}}\).
            </p>

            <p>
                Note that the test statistic \(t\) follows a <em>t-distribution</em> with degrees of freedom given by:
                \[
                \text{df} = n_{1} + n_{2} - 2.
                \]
            </p>

            <p>
                A \(100(1 - \alpha)\%\) confidence interval for \(\mu_{1} - \mu_{2}\) is given by:
                \[
                (\bar{x}_{1} - \bar{x}_{2}) \pm t \cdot s_{p} \sqrt{\frac{1}{n_{1}} + \frac{1}{n_{2}}}
                \]
            </p>

            <p>
                Here, the value of \(t\) is obtained from the <em>t-distribution</em> corresponding to the desired
                confidence level and
                \(n_{1} + n_{2} - 2\) degrees of freedom.
            </p>

            <p>
                Python allows us to conduct a <i>pooled t-test</i> using the <code>ttest_ind_from_stats()</code>
                over the <code>stats</code> module from the <code>scipy</code> package.
            </p>

            <p>
                We will again load the <code>students</code> data set:
            </p>

            <pre class="plain"><code>>>> import pandas as pd
>>> import numpy as np
>>> 
>>> students = pd.read_csv("https://userpage.fu-berlin.de/soga/data/raw-data/students.csv")</code></pre>

            <p>
                We will examine the mean annual salary (in Euros) of graduates to determine whether
                there are statistically significant differences between male and female students. The key question is
                whether gender influences the mean salary of graduates.
            </p>

            <p>
                In order to do this we need to first prepare the data. The following code speaks for itself:
            </p>

            <pre class="plain"><code>>>> graduated_students = students.loc[students.graduated == 1]
>>> males_graduated = graduated_students.loc[students.gender == "Male"]
>>> females_graduated = graduated_students.loc[students.gender == "Female"]
>>> 
>>> n = 50
>>> 
>>> sample_males = males_graduated.sample(n, random_state = 9)["salary"]
>>> sample_females = females_graduated.sample(n, random_state = 9)["salary"]
>>> print(np.mean(sample_males))
47262.417382791995
>>> print(np.mean(sample_females))
35825.54641661087</code></pre>

            <p>
                We test the normaility assumption by plotting a normal probability plot,
                often referred to as <a href="https://en.wikipedia.org/wiki/Q%E2%80%93Q_plot" target="_blank">Q-Q
                    plot</a>.
                If the variable is normally distributed, the normal probability plot should be roughly linear.
            </p>

            <p>
                We will switch to VS Code to write the following code and display the graph.
            </p>

            <pre class="plain"><code># Rest of the code
import matplotlib.pyplot as plt
import scipy.stats as stats

plt.figure(figsize=(12,5))

ax = plt.subplot(1, 2, 1)
qq = stats.probplot(sample_males, dist="norm", plot = plt)
ax.set_title("Q-Q plot for males (sample)")
ax.set_ylabel("Sample quantiles")

ax = plt.subplot(1, 2, 2)
qq = stats.probplot(sample_females, dist="norm", plot = plt)
ax.set_title("Q-Q plot for females (sample)")
ax.set_ylabel("Sample quantiles")

plt.show(block=True)</code></pre>

            <div class="img-div">
                <img src="images/qq_plot_male_female_salary.png" alt="two-sided critical value">
            </div>

            <p>
                We see that the sample data is somehow noisy, but it is still roughly normally distributed. The
                deviations from the straight line in the upper and lower parts suggest, that the probability
                distribution is slightly skewed.
            </p>

            <p>
                Further, we check if the standard deviations of the two populations are roughly equal. As a rule of
                thumb, the condition of equal population standard deviations is met, if the ratio of the larger to the
                smaller sample standard deviation is less than 2 (<a
                    href="https://www.sciencedirect.com/book/monograph/9780128043172/introductory-statistics"
                    target="_blank">Weiss, 2010</a>). Let us assume, that the data of the
                students data set is a good approximation for the population.
            </p>

            <pre class="plain"><code>>>> print(np.std(sample_males, ddof = 1))
9576.164209488374
>>> print(np.std(sample_females, ddof = 1))
7200.9719569940535
>>> print(np.std(sample_males, ddof = 1) / np.std(sample_females, ddof = 1))
1.3298432859729967</code></pre>

            <p>
                The ratio is approximately \(1.33\) and thus, we conclude that the equal population standard deviations
                criterion is fulfilled. A simple visualization technique for evaluating the spread of a variable is to
                use a box plot.
            </p>

            <pre class="plain"><code># Rest of the code

import seaborn as sns

plt.figure(figsize=(11,5))

sample_df = pd.melt(pd.DataFrame({'male': sample_males.values,
                                  'female': sample_females.values}))
sample_df.columns = ["Gender", "Annual salary in EUR"]

sns.boxplot(x='Gender', y='Annual salary in EUR', data=sample_df).set(title='Sample data')

plt.show(block=True)</code></pre>

            <div class="img-div">
                <img src="images/box_plot_male_female_salary.png" alt="two-sided critical value">
            </div>

            <p>
                We now conduct the pooled t-test using an already available Python package.
            </p>

            <pre
                class="plain"><code>>>> from scipy import stats
>>> 
>>> test_result = stats.ttest_ind(sample_males, sample_females, 
...                               equal_var = True, 
...                               alternative = "greater")
>>>
>>> test_result
TtestResult(statistic=np.float64(6.7496330142831065), pvalue=np.float64(5.25205313471519e-10), df=np.float64(98.0))</code></pre>

            <p>
                We may conclude that at the 1% significance level, the data provides very strong evidence to conclude
                that the average salary of male graduates is higher than the average salary of female graduates.
            </p>

            <hr>

            <span id="TwoPopulationMeansUnequalSD"><b>Inference for Two Independent Population Means with Unequal
                    Standard Deviations</b></span>

            <p>
                In cases where we want to test for two population means and the standard deviations are different
                between the
                two populations, the so-called non-pooled t-test, or
                <a href="https://en.wikipedia.org/wiki/Welch's_t-test" target="_blank">Welch’s t-test</a>, is applied.
            </p>

            <p>
                The non-pooled t-test is very similar to the pooled t-test, except for the test statistic \(t\) and the
                calculation of the degrees of freedom (\(df\)). The test statistic does not use \(s_p\), the pooled
                standard
                deviation, and is written as:
                \[
                t = \frac{\bar{x}_{1} - \bar{x}_{2}}
                {\sqrt{\frac{s^{2}_{1}}{n_{1}} + \frac{s^{2}_{2}}{n_{2}} }}
                \]
            </p>

            <p>
                The denominator of the equation above is the estimator of the standard deviation of
                \(\bar{x}_1 - \bar{x}_2\), denoted \(s_{\bar{x}_1-\bar{x}_2}\).
            </p>

            <p>
                The test statistic \(t\) has a t-distribution, and the degrees of freedom (df) are given by
                \[
                df=\frac{\left(\frac{s_1^2}{n_1}+\frac{s_2^2}{n_2}\right)^2}
                {\frac{\left(\frac{s_1^2}{n_1}\right)^2}{n_1-1}
                +\frac{\left(\frac{s_2^2}{n_2}\right)^2}{n_2-1}} \text{.}
                \]
            </p>

            <p>
                The non-pooled t-test is robust to moderate violations of the normal population assumption, but it is
                less
                robust to outliers (<a
                    href="https://www.sciencedirect.com/book/monograph/9780128043172/introductory-statistics"
                    target="_blank">Weiss, 2010</a>).
            </p>
            <p>
                The \(100(1-\alpha)\%\) confidence interval for \(\mu_1 - \mu_2\) is given by
            </p>

            <p>
                \[
                (\bar{x}_1 - \bar{x}_2)\; \pm\; t^{\ast}
                \cdot
                \sqrt{\frac{s_1^{2}}{n_1} + \frac{s_2^{2}}{n_2}}
                \]
            </p>

            <p>
                where the value of t is obtained from the t-distribution for the given confidence level. The degrees of
                freedom (df) and obtained using the equation above.
            </p>

            <p>
                In order to illustrate the non-pooled t-test, we examine the mean annual salary (in euros) of female
                graduates with respect to their major field of study. Specifically, we want to investigate whether there
                is a statistically significant difference in the mean salaries of two populations: female students
                majoring in Political Science and female students majoring in Social Sciences.
            </p>

            <p>
                The following example, written in VS Code, speaks for itself:
            </p>

            <pre class="plain"><code>female_graduated_students = students.loc[(students.graduated == 1) & (students.gender == "Female")]
political_sc = female_graduated_students.loc[female_graduated_students.major == "Political Science"]
social_sc = female_graduated_students.loc[female_graduated_students.major == "Social Sciences"]

n = 50

sample_polt_sc = political_sc.sample(n, random_state = 9)["salary"]
sample_social_sc = social_sc.sample(n, random_state = 9)["salary"]</code></pre>

            <p>
                We check whether the data are normally distributed by plotting a Q–Q plot, as we did before:
            </p>

            <pre class="plain"><code>plt.figure(figsize=(12,5))

ax = plt.subplot(1, 2, 1)
qq = stats.probplot(sample_polt_sc, dist="norm", plot = plt)
ax.set_title("Q-Q plot for female graduates of \nPolitical Science (sample data)")
ax.set_ylabel("Sample quantiles")

ax = plt.subplot(1, 2, 2)
qq = stats.probplot(sample_social_sc, dist="norm", plot = plt)
ax.set_title("Q-Q plot for female graduates of \nSocial Sciences (sample data)")
ax.set_ylabel("Sample quantiles")

plt.show(block=True)</code></pre>

            <div class="img-div">
                <img src="images/qq_plot_political_social_salary.png" alt="Q-Q plots for sample data">
            </div>

            <p>
                The data from both samples fall mostly along a straight line. Therefore, we assume that the data in the
                students dataset provide a reasonable approximation to the population. We can then visually assess whether the
                standard deviations of the two populations differ by plotting a box plot.
            </p>

            <pre class="plain"><code>sample_polt_sc = political_sc.sample(n, random_state = 9)
sample_social_sc = social_sc.sample(n, random_state = 9)

plt.figure(figsize=(11,5))

df = pd.DataFrame({'salary' : np.concatenate([sample_social_sc["salary"].values, sample_polt_sc["salary"].values]),
                   'major'  : np.concatenate([sample_social_sc["major"].values, sample_polt_sc["major"].values])},
                  columns = ['salary', 'major'])

sns.boxplot(
    data=df,
    x="salary",
    y="major"
).set(
    title='Population data',
    xlabel='Annual salary in EUR',
    ylabel=''
)

plt.show(block=True)</code></pre>

            <div class="img-div">
                <img src="images/box_plot_political_social_salary.png" alt="Box plots for sample data">
            </div>

            <p>
                Based on the graphical evaluation, we conclude that the data are roughly normally distributed and that
                the standard deviations differ from each other.
            </p>

            <p>
                We now conduct the non-pooled t-test using an existing Python package.
            </p>

            <pre class="plain"><code>>>> from scipy import stats
>>>
>>> test_result = stats.ttest_ind(sample_polt_sc["salary"], sample_social_sc["salary"], equal_var = False)
>>>
>>> print("t-value:", round(test_result.statistic, 5))
t-value: 2.62318
>>> print("p-value:", round(test_result.pvalue, 5))
p-value: 0.01025</code></pre>

            <p>
                Again, we may conclude that, at the 5% significance level, the data provide strong evidence that
                the average annual salary of female graduates in Political Science differs from the average annual salary of
                female graduates in Social Sciences.
            </p>

            <p><i style="color: red;">Incomplete!</i></p>

            <hr>

</body>

</html>

<!--
Excerpts from randomservices.org, which I might add later.

            <p>
                Our starting point for these tests will usually be a random sample
                \( \mathbf{X} = (X_1, X_2, \dots, X_n) \)
                from a normal distribution whose mean \(\mu\) and variance \(\sigma^2\) may or may not be known.
            </p>

            <p>
                The basic <i>test statistics</i>, the sample mean \(M\) and the sample variance \(S^2\), are defined as
                \[
                M = \frac{1}{n} \sum_{i=1}^n X_i, \quad
                S^2 = \frac{1}{n - 1} \sum_{i=1}^n (X_i - M)^2
                \]
            </p>

            <p>
                Both \(M\) and \(S^2\) are <i>unbiased</i> and <i>consistent</i> estimators of \(\mu\) and \(\sigma^2\),
                respectively.
            </p>

            <p>
                From these basic statistics, we can construct other test statistics that are quite useful for hypothesis
                testing, namely:
                \[
                Z = \frac{M - \mu}{\sigma / \sqrt{n}}, \quad
                T = \frac{M - \mu}{S / \sqrt{n}}, \quad
                V = \frac{n - 1}{\sigma^2} S^2
                \]
            </p>

            <p>In the above:</p>

            <ul>
                <li>\(Z\) has the standard normal distribution.</li>
                <li>\(T\) has the Student \(t\)-distribution with \(n - 1\) degrees of freedom.</li>
                <li>\(V\) has the chi-square distribution with \(n - 1\) degrees of freedom.</li>
                <li>\(Z\) and \(V\) are independent.</li>
            </ul>

            <p>
                Let us now consider the <b>one-sample t-test</b>. It is reasonable to use this test when you have a
                single
                sample of data, you know the population mean you want to compare against, the population standard
                deviation is
                unknown, and the data is approximately normally distributed (especially for small samples).
            </p>

            <p>
                We first set the significance level \( \alpha \in (0,1)\). Let \(t_k(p)\) denote the quantile of order
                \(p\)
                for the Student \(t\)-distribution with \(k\) degrees of freedom.
            </p>
-->